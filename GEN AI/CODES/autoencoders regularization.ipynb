{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca690731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d0800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884542f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784  \n",
    "encoding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7eed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(input_size,))\n",
    "encoded = Dense(256, activation='relu')(input_img)\n",
    "encoded = Dropout(0.5)(encoded)  # Dropout for regularization\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(256, activation='relu')(encoded)\n",
    "decoded = Dense(input_size, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1aa299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9899a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4c98d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               201488    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468,368\n",
      "Trainable params: 468,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1be561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 13s 23ms/step - loss: 0.1806 - val_loss: 0.1158\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.1296 - val_loss: 0.1027\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1218 - val_loss: 0.0978\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.1176 - val_loss: 0.0944\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1151 - val_loss: 0.0924\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1131 - val_loss: 0.0911\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1117 - val_loss: 0.0899\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1104 - val_loss: 0.0893\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1092 - val_loss: 0.0887\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1084 - val_loss: 0.0877\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99759afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79750f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(input_size,))\n",
    "encoded = Dense(256, activation='relu', activity_regularizer=regularizers.l2(0.01))(input_img)\n",
    "encoded = Dropout(0.5)(encoded)  # Dropout for regularization\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l2(0.01))(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5764afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = Dense(256, activation='relu', activity_regularizer=regularizers.l2(0.01))(encoded)\n",
    "decoded = Dense(input_size, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87eee331",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba61743",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0288bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 784)               201488    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468,368\n",
      "Trainable params: 468,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed09b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.3525 - val_loss: 0.2773\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.2678 - val_loss: 0.2551\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.2525 - val_loss: 0.2407\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.2383 - val_loss: 0.2250\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.2264 - val_loss: 0.2121\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.2168 - val_loss: 0.2027\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.2104 - val_loss: 0.1969\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.2055 - val_loss: 0.1922\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.2010 - val_loss: 0.1876\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1984 - val_loss: 0.1869\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bc52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(input_size,))\n",
    "encoded = Dense(256, activation='relu', activity_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01))(input_img)\n",
    "encoded = Dropout(0.5)(encoded)  # Dropout for regularization\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01))(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ddb648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = Dense(256, activation='relu', activity_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01))(encoded)\n",
    "decoded = Dense(input_size, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a52cfe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9218e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bac8b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 784)               201488    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468,368\n",
      "Trainable params: 468,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e326a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 10s 18ms/step - loss: 0.6273 - val_loss: 0.5538\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.5054 - val_loss: 0.4641\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.4323 - val_loss: 0.4053\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.3840 - val_loss: 0.3659\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.3512 - val_loss: 0.3388\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.3284 - val_loss: 0.3196\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.3122 - val_loss: 0.3058\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.3004 - val_loss: 0.2957\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.2917 - val_loss: 0.2881\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.2852 - val_loss: 0.2824\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee879913",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10d6a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0a16846",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 \n",
    "encoding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77da9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GaussianNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8c99ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(input_size,))\n",
    "noisy_input = GaussianNoise(0.5)(input_img)  \n",
    "encoded = Dense(encoding_dim, activation='relu')(noisy_input)\n",
    "decoded = Dense(input_size, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d76fc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aa601d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2024776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 784)              0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 784)               101136    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,616\n",
      "Trainable params: 201,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "denoising_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85bb384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 13s 26ms/step - loss: 0.2171 - val_loss: 0.1521\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1679 - val_loss: 0.1362\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1600 - val_loss: 0.1292\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1557 - val_loss: 0.1260\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1529 - val_loss: 0.1232\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1509 - val_loss: 0.1217\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1494 - val_loss: 0.1201\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1480 - val_loss: 0.1192\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1471 - val_loss: 0.1192\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1464 - val_loss: 0.1178\n"
     ]
    }
   ],
   "source": [
    "history = denoising_autoencoder.fit(X_train_noisy, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test_noisy, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9628aacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 784)               101136    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,616\n",
      "Trainable params: 201,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.1852 - val_loss: 0.1250\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1134 - val_loss: 0.1029\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0986 - val_loss: 0.0938\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0921 - val_loss: 0.0894\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0884 - val_loss: 0.0864\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0858 - val_loss: 0.0844\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0840 - val_loss: 0.0828\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0825 - val_loss: 0.0815\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0813 - val_loss: 0.0805\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0803 - val_loss: 0.0796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1996826b5b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "\n",
    "input_size = 784  \n",
    "encoding_dim = 128\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(1e-4))(input_img)\n",
    "decoded = Dense(input_size, activation='sigmoid')(encoded)\n",
    "\n",
    "sparse_autoencoder = Model(input_img, decoded)\n",
    "\n",
    "sparse_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "sparse_autoencoder.summary()\n",
    "\n",
    "sparse_autoencoder.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eccf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bd96d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pythonn\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1712 - val_loss: 0.1083\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0955 - val_loss: 0.0844\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.0807 - val_loss: 0.0761\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.0749 - val_loss: 0.0726\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0720 - val_loss: 0.0705\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0704 - val_loss: 0.0693\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.0693 - val_loss: 0.0685\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0686 - val_loss: 0.0679\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0680 - val_loss: 0.0675\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 0.0676 - val_loss: 0.0671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19966716520>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define input size\n",
    "input_size = 784\n",
    "\n",
    "# Define the shared layer (encoder)\n",
    "shared_layer = Dense(128, activation='relu')\n",
    "\n",
    "# Define the input tensor\n",
    "input_tensor = Input(shape=(input_size,))\n",
    "\n",
    "# Apply the shared layer to the input tensor\n",
    "encoded = shared_layer(input_tensor)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder_model = Model(input_tensor, encoded)\n",
    "\n",
    "# Define the decoding layer with tied weights\n",
    "decoded = Dense(input_size, activation='sigmoid')(encoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_tensor, decoded)\n",
    "\n",
    "# Compile the model and train it\n",
    "# (Note: You would typically use a larger dataset for training)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5144cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 37s 77ms/step - loss: 0.1705 - val_loss: 0.1082\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.0958 - val_loss: 0.0850\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.0810 - val_loss: 0.0764\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0750 - val_loss: 0.0726\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.0721 - val_loss: 0.0705\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0704 - val_loss: 0.0694\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0693 - val_loss: 0.0685\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0686 - val_loss: 0.0680\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0681 - val_loss: 0.0675\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0676 - val_loss: 0.0671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1996675b5b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_size = 784\n",
    "\n",
    "shared_layer = Dense(128, activation='relu')\n",
    "\n",
    "input_tensor = Input(shape=(input_size,))\n",
    "\n",
    "encoded = shared_layer(input_tensor)\n",
    "\n",
    "encoder_model = Model(input_tensor, encoded)\n",
    "\n",
    "decoded = Dense(input_size, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_tensor, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1341ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
